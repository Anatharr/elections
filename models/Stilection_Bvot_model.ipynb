{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "\n",
    "original_data_canton_FR = pd.read_excel(r'../dataset/raw/Dep_15_Resultats_T1_complet.xlsx', sheet_name='Cantons', header=2)\n",
    "# original_data_Bvot_FR        = pd.read_csv('../dataset/inputs/XDataFR_Bvot.csv', sep=';')\n",
    "# original_data_Bvot_targets_FR = pd.read_csv('../dataset/labels/yDataFR_Bvot.csv', sep=';')\n",
    "\n",
    "data_canton_FR = original_data_canton_FR.copy()\n",
    "# data_Bvot_FR   = original_data_Bvot_FR.copy()\n",
    "# data_Bvot_targets_FR = original_data_Bvot_targets_FR.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# fonction utile #############################\n",
    "def saveData(data, loc):\n",
    "    # save cher_data as excel\n",
    "    writer = pd.ExcelWriter(loc)\n",
    "    \n",
    "    # write dataframe to excel\n",
    "    data.to_excel(writer)\n",
    "\n",
    "    # save the excel\n",
    "    writer.save()\n",
    "\n",
    "############################# Format des donnees brute ##############################\n",
    "\n",
    "def getNbBinomes(data):\n",
    "    return len([header for header in data.columns if \"Binôme\" in header])\n",
    "\n",
    "def explodeLines(data):\n",
    "    initdf = data[['Code du département', 'Libellé du département', 'Code du canton', \n",
    "            'Libellé du canton', 'Inscrits', 'Abstentions', '% Abs/Ins', 'Votants',\n",
    "            '% Vot/Ins', 'Blancs', '% Blancs/Ins', '% Blancs/Vot', 'Nuls', '% Nuls/Ins',\n",
    "            '% Nuls/Vot', 'Exprimés', '% Exp/Ins', '% Exp/Vot']]\n",
    "\n",
    "    headers = ['N°Panneau', 'Nuance', 'Binôme', 'Sièges', 'Voix', '% Voix/Ins', '% Voix/Exp']\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for i in range(getNbBinomes(data)):\n",
    "        partidf = data[[h+'.'+str(i) if i!=0 else h for h in headers]]\n",
    "        partidf = pd.concat([initdf, partidf], axis=1)\n",
    "        partidf.columns = pd.Index(initdf.columns.values.tolist() + headers)\n",
    "        df = pd.concat([df, partidf])\n",
    "    \n",
    "    # Remove useless rows   \n",
    "    df = df.dropna(how='all', subset=headers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explode line \n",
    "data_canton_FR = explodeLines(data_canton_FR)"
   ]
  },
  {
   "source": [
    "## Dictionnaire des duels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Dictionnaire des duels #####################################\n",
    "\n",
    "def getNuanceOfElected(data, col_siege='Sièges', col_nuance='Nuance'):\n",
    "    elected = data[data[col_siege]=='Elus']\n",
    "    return list(elected[col_nuance]) if len(elected)!=0 else None\n",
    "\n",
    "def filterBestNuances(data, col_nuance='Nuance', criteria=12.50):\n",
    "    bestCandidat = data[data['% Voix/Ins']>= criteria]\n",
    "    \n",
    "    if bestCandidat.empty or len(bestCandidat)==1:\n",
    "        bestCandidat = data.sort_values(by='Voix', ascending=False).iloc[0:2,:]\n",
    "\n",
    "    return list(bestCandidat[col_nuance])\n",
    "\n",
    "def getDuels(data, dep, col_dep='Code du département', col_canton='Code du canton', col_siege='Sièges', col_nuance='Nuance',count=None):\n",
    "    '''\n",
    "        ATTENTION : data doit etre EXPLODE !\n",
    "    '''\n",
    "    data = data[data[col_dep]==dep]\n",
    "    duels = dict()\n",
    "    for canton in data[col_canton].unique():\n",
    "        data_canton = data[data[col_canton]==canton]\n",
    "        # allow to know if there is a majority in the canton\n",
    "        elected = getNuanceOfElected(data_canton, col_siege=col_siege, col_nuance=col_nuance) \n",
    "        \n",
    "        if elected is not None:\n",
    "            count+=1\n",
    "            duels[str(canton)]= elected\n",
    "        else:\n",
    "            duels[str(canton)] = filterBestNuances(data_canton)\n",
    "    return (duels, count) if count is not None else duels\n",
    "\n",
    "def optimizeDuelDict(duels):\n",
    "    optdic = dict()\n",
    "    for dep, duelDepDict in duels.items():\n",
    "        for canton, duelList in duelDepDict.items():\n",
    "            key = ':'.join(duelList)\n",
    "            if key in optdic.keys():\n",
    "                optdic[key].append((dep, canton))\n",
    "            else:\n",
    "                optdic[key]= [(dep, canton)]\n",
    "    return optdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#dictionnaire des duels\n",
    "duels = dict()\n",
    "count=0\n",
    "for dep in data_canton_FR['Code du département'].unique():\n",
    "    duels[str(dep)], count= getDuels(data_canton_FR, dep, count=count)\n",
    "    if duels[str(dep)]==[]:\n",
    "        print('empty list for dep : ', dep)\n",
    "\n",
    "#dictionnaire ooptimize\n",
    "optDuels = optimizeDuelDict(duels)\n",
    "win = [duel.split(':') for duel in list(optDuels.keys()) if len(duel.split(':'))<2]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('2', '20'), ('52', '8'), ('83', '5'), ('84', '14')]"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "duels['14']\n",
    "count=0\n",
    "for winner in win:\n",
    "    count += len(optDuels[winner[0]])\n",
    "count\n",
    "optDuels[win[0][0]]"
   ]
  },
  {
   "source": [
    "## Preparation des donnees pour le reseau de neuronne"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### Data Processing ####################################\n",
    "\n",
    "def prepareInputDataExploded(data):\n",
    "    tmp = data[['NUMTOUR', 'CODDPT', 'CODSUBCOM', 'LIBSUBCOM', 'CODBURVOT', 'CODCAN',\n",
    "            'LIBCAN', 'NBRINS', 'NBRVOT', 'NBREXP', 'CODNUA', 'NBRVOIX']].copy()\n",
    "    correction = [str(i) for i in range(1,10)]\n",
    "    #remove canton where there is a winner in the 1st turn\n",
    "    for winner in win:\n",
    "         for dep, can in optDuels[winner[0]]:\n",
    "            if dep in correction:\n",
    "                tmp = tmp.loc[~((tmp['CODDPT']=='0'+dep) & (tmp['CODCAN']==int(can)))]\n",
    "            else:\n",
    "                tmp = tmp.loc[~((tmp['CODDPT']==dep) & (tmp['CODCAN']==int(can)))]\n",
    "    \n",
    "\n",
    "\n",
    "    # Compute missing data\n",
    "    tmp['NBRABS'] = tmp['NBRINS'] - tmp['NBRVOT']\n",
    "    tmp['NBRBLCNUL'] = tmp['NBRVOT'] - tmp['NBREXP']\n",
    "    tmp['%ABS/INS'] = tmp['NBRABS'] / tmp['NBRINS']\n",
    "    tmp['%BLCNUL/VOT'] = tmp['NBRBLCNUL'] / tmp['NBRVOT']\n",
    "    tmp['%EXP/VOT'] = tmp['NBREXP'] / tmp['NBRVOT']\n",
    "    tmp['%VOIX/EXP'] = tmp['NBRVOIX'] / tmp['NBREXP']\n",
    "\n",
    "    nuances = getAllNuances(data)\n",
    "    statsFeatures = ['NBRINS', 'NBREXP', '%ABS/INS', '%BLCNUL/VOT', '%EXP/VOT']\n",
    "    idFeatures = ['CODDPT', 'CODCAN', 'CODSUBCOM', 'CODBURVOT']\n",
    "\n",
    "    exprimes = tmp[idFeatures + ['NBREXP']].drop_duplicates().sort_values(idFeatures)['NBREXP']\n",
    "    stats = tmp[idFeatures + statsFeatures].drop_duplicates()[statsFeatures]\n",
    "    ids = tmp[idFeatures].drop_duplicates()\n",
    "\n",
    "    # Create [%Voix] and fill it\n",
    "    voix = pd.DataFrame(0, index=data.index, columns=nuances)\n",
    "    for parti in nuances:\n",
    "        voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
    "    voix = pd.concat([tmp[idFeatures], voix], axis=1).groupby(idFeatures).sum()[nuances]\n",
    "    voix.index = exprimes.index\n",
    "\n",
    "    # Concat with computed stats and divide almost everything by Exprimés\n",
    "    voix = voix.divide(exprimes, axis=0)\n",
    "    X = pd.concat([stats, voix], axis=1)\n",
    "    X.index = pd.MultiIndex.from_frame(ids)\n",
    "    return X.sort_values(['CODDPT', 'CODCAN', 'CODSUBCOM', 'CODBURVOT'])\n",
    "\n",
    "def getAllNuances(data, colNuance='CODNUA', fmt='exploded'):\n",
    "    if fmt not in ['exploded', 'line']:\n",
    "        raise ValueError(\"format parameter must be 'exploded' or 'line'\")\n",
    "    \n",
    "    if fmt == 'exploded':\n",
    "        nuances = data[colNuance].unique()\n",
    "    \n",
    "    if fmt == 'line':\n",
    "        nuances = np.array([])\n",
    "        nuances_tmp = data[colNuance].fillna(0)\n",
    "        for c in nuances_tmp:\n",
    "            nuances = np.append(nuances, nuances_tmp[c])\n",
    "        nuances = np.unique(nuances[nuances!=0])\n",
    "    \n",
    "    return sorted(nuances)\n",
    "\n",
    "# retourne un dataset \n",
    "def getTrainSets(X, y, duel, col_canton='CODCAN', col_dep='Code du département'):\n",
    "    mask_dep    = pd.Series([False]*len(X))\n",
    "    mask_canton = pd.Series([False]*len(X))\n",
    "    for dep in X[col_dep].unique():\n",
    "        for canton in X[X[col_dep]==dep][col_canton].unique(): #pour chaque canton du departement\n",
    "            #on considere que les cantons qui ont comme partis les partis du duel\n",
    "            if all(nuance in X.loc[(X[col_dep]==dep) & (X[col_canton]==canton)] for nuance in duel):\n",
    "                mask_dep    |= X[col_dep]==dep\n",
    "                mask_canton |= X[col_canton]==canton\n",
    "\n",
    "    # filtre les departement dont aucun canton contient notre duel\n",
    "    X= X[mask_dep]\n",
    "    y = y[mask_dep]\n",
    "    return (X[mask_canton], y[mask_canton])\n",
    "\n",
    "def prepareLabelsExploded(data, oneHotEncode=False):\n",
    "    nuances = getAllNuances(data)\n",
    "    idFeatures = ['CODDPT', 'CODCAN', 'CODSUBCOM', 'CODBURVOT']\n",
    "\n",
    "    exprimes = data[idFeatures+['NBREXP']].groupby(idFeatures).first()\n",
    "\n",
    "    # Create [%Voix] and fill it\n",
    "    voix = pd.DataFrame(0, index=data.index, columns=nuances)\n",
    "    for parti in nuances:\n",
    "        voix[parti][data['CODNUA']==parti] = data[data['CODNUA']==parti]['NBRVOIX']\n",
    "    voix = pd.concat([data[idFeatures], voix], axis=1).groupby(idFeatures).sum().sort_values(idFeatures)[nuances]\n",
    "\n",
    "    # Concat with computed stats and divide voix by exprimes\n",
    "    y = voix.divide(exprimes['NBREXP'], axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'NUMTOUR' :    'int64',\n",
    "    'CODDPT' :    'object',\n",
    "    'CODSUBCOM' :  'int64',\n",
    "    'LIBSUBCOM' : 'object',\n",
    "    'CODBURVOT' : 'object',\n",
    "    'CODCAN' :     'int64',\n",
    "    'LIBCAN' :    'object',\n",
    "    'NBRINS' :     'int64',\n",
    "    'NBRVOT' :     'int64',\n",
    "    'NBREXP' :     'int64',\n",
    "    'NUMDEPCAND' : 'int64',\n",
    "    'LIBLISEXT' : 'object',\n",
    "    'CODNUA' :    'object',\n",
    "    'NBRVOIX' :    'int64',\n",
    "}\n",
    "\n",
    "#load data\n",
    "dataBvot = pd.read_csv('../dataset/raw/DP15_Bvot_T1T2.csv', delimiter=';', dtype=dtypes)\n",
    "dataT1Bvot = dataBvot[dataBvot.NUMTOUR==1]\n",
    "dataT2Bvot = dataBvot[dataBvot.NUMTOUR==2]\n",
    "\n",
    "# dataT1Bvot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Preparing input data... <ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "<ipython-input-22-061e0ee9259f>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  voix[parti][data['CODNUA']==parti] = tmp[tmp['CODNUA']==parti]['NBRVOIX']\n",
      "Preparing labels... shape X = (60975, 24) shape y = (60975, 18)\n"
     ]
    }
   ],
   "source": [
    "## preparing data\n",
    "\n",
    "\n",
    "print('Preparing input data... ', end='')\n",
    "X = prepareInputDataExploded(dataT1Bvot)\n",
    "\n",
    "\n",
    "print('Preparing labels... ', end='')\n",
    "y = prepareLabelsExploded(dataT2Bvot)\n",
    "\n",
    "print(f'shape X = {X.shape} shape y = {y.shape}')\n"
   ]
  },
  {
   "source": [
    "## build model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(160,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(tf.keras.layers.Dense(20, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-26ab0e19e13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainset, y, batch_size=32, validation_data=(testset, y), epochs=100, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(trainset, y, verbose=0)\n",
    "_, test_acc = model.evaluate(testset, y, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  }
 ]
}